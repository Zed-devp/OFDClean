{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read datasets and senses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "      ID   A   B   C\n",
      "0    t1  a1  b1  c3\n",
      "1    t2  a1  b1  c6\n",
      "2    t3  a1  b2  c1\n",
      "3    t4  a1  b2  c2\n",
      "4    t5  a1  b2  c3\n",
      "5    t6  a1  b2  c4\n",
      "6    t7  a2  b2  c2\n",
      "7    t8  a2  b2  c4\n",
      "8    t9  a2  b2  c4\n",
      "9   t10  a2  b3  c5\n",
      "10  t11  a2  b3  c3\n",
      "11  t12  a2  b3  c3\n",
      "\n",
      "sense_dict:\n",
      " {'1': ['c1', 'c2', 'c3'], '2': ['c2', 'c4'], '3': ['c1', 'c4', 'c5'], '4': ['c2', 'c3', 'c5'], '5': ['c1', 'c2', 'c5'], '6': ['c4', 'c6'], '7': ['c1', 'c4', 'c6', 'c7']}\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import read_data, sense2dict\n",
    "\n",
    "data_path = 'data.csv'\n",
    "senses_path = 'senses.csv'\n",
    "\n",
    "data, sense_dict = read_data(data_path, senses_path)\n",
    "\n",
    "print('data:\\n', data)\n",
    "print('\\nsense_dict:\\n', sense_dict)  # sense->synonym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert sense table to ssets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssets:\n",
      " {'c1': ['1', '3', '5', '7'], 'c2': ['1', '2', '4', '5'], 'c3': ['1', '4'], 'c4': ['2', '3', '6', '7'], 'c5': ['3', '4', '5'], 'c6': ['6', '7'], 'c7': ['7']}\n"
     ]
    }
   ],
   "source": [
    "ssets = {}  # synonym->sense\n",
    "for sense, synonym in sense_dict.items():\n",
    "    for value in synonym:\n",
    "        if value not in ssets.keys():\n",
    "            ssets[value] = []\n",
    "        ssets[value].append(sense)\n",
    "\n",
    "print('ssets:\\n', ssets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize attribute columns here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attrs1: ['a1' 'a2']\n",
      "attrs2: ['b1' 'b2' 'b3']\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import get_attribute\n",
    "\n",
    "col_name1 = 'A'\n",
    "attrs1 = get_attribute(data, col_name1)\n",
    "\n",
    "col_name2 = 'B'\n",
    "attrs2 = get_attribute(data, col_name2)\n",
    "\n",
    "right_col_name = 'C'\n",
    "\n",
    "print('attrs1:', attrs1)\n",
    "print('attrs2:', attrs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute an initial assignment for every equivalence class $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 5\n",
      "sorted_synonyms ['c3', 'c6', 'c1', 'c2', 'c4']\n",
      "sorted_senses [['1', '4'], ['6', '7'], ['1', '3', '5', '7'], ['1', '2', '4', '5'], ['2', '3', '6', '7']]\n",
      "topk:\n",
      " [['1', '4'], ['6', '7'], ['1', '3', '5', '7'], ['1', '2', '4', '5'], ['2', '3', '6', '7']]\n",
      "topk:\n",
      " [['1', '4'], ['6', '7'], ['1', '3', '5', '7'], ['1', '2', '4', '5']]\n",
      "topk:\n",
      " [['1', '4'], ['6', '7'], ['1', '3', '5', '7']]\n",
      "topk:\n",
      " [['1', '4'], ['6', '7']]\n",
      "topk:\n",
      " [['1', '4']]\n",
      "x:\n",
      "     A   C\n",
      "0  a1  c3\n",
      "1  a1  c6\n",
      "2  a1  c1\n",
      "3  a1  c2\n",
      "4  a1  c3\n",
      "5  a1  c4\n",
      "k= 4\n",
      "sorted_synonyms ['c4', 'c3', 'c2', 'c5']\n",
      "sorted_senses [['2', '3', '6', '7'], ['1', '4'], ['1', '2', '4', '5'], ['3', '4', '5']]\n",
      "topk:\n",
      " [['2', '3', '6', '7'], ['1', '4'], ['1', '2', '4', '5'], ['3', '4', '5']]\n",
      "topk:\n",
      " [['2', '3', '6', '7'], ['1', '4'], ['1', '2', '4', '5']]\n",
      "topk:\n",
      " [['2', '3', '6', '7'], ['1', '4']]\n",
      "topk:\n",
      " [['2', '3', '6', '7']]\n",
      "x:\n",
      "      A   C\n",
      "6   a2  c2\n",
      "7   a2  c4\n",
      "8   a2  c4\n",
      "9   a2  c5\n",
      "10  a2  c3\n",
      "11  a2  c3\n",
      "k= 2\n",
      "sorted_synonyms ['c3', 'c6']\n",
      "sorted_senses [['1', '4'], ['6', '7']]\n",
      "topk:\n",
      " [['1', '4'], ['6', '7']]\n",
      "topk:\n",
      " [['1', '4']]\n",
      "x:\n",
      "     B   C\n",
      "0  b1  c3\n",
      "1  b1  c6\n",
      "k= 4\n",
      "sorted_synonyms ['c4', 'c2', 'c1', 'c3']\n",
      "sorted_senses [['2', '3', '6', '7'], ['1', '2', '4', '5'], ['1', '3', '5', '7'], ['1', '4']]\n",
      "topk:\n",
      " [['2', '3', '6', '7'], ['1', '2', '4', '5'], ['1', '3', '5', '7'], ['1', '4']]\n",
      "topk:\n",
      " [['2', '3', '6', '7'], ['1', '2', '4', '5'], ['1', '3', '5', '7']]\n",
      "topk:\n",
      " [['2', '3', '6', '7'], ['1', '2', '4', '5']]\n",
      "x:\n",
      "     B   C\n",
      "2  b2  c1\n",
      "3  b2  c2\n",
      "4  b2  c3\n",
      "5  b2  c4\n",
      "6  b2  c2\n",
      "7  b2  c4\n",
      "8  b2  c4\n",
      "k= 2\n",
      "sorted_synonyms ['c3', 'c5']\n",
      "sorted_senses [['1', '4'], ['3', '4', '5']]\n",
      "topk:\n",
      " [['1', '4'], ['3', '4', '5']]\n",
      "x:\n",
      "      B   C\n",
      "9   b3  c5\n",
      "10  b3  c3\n",
      "11  b3  c3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from algorithms.init_assign import init_assign\n",
    "\n",
    "initial_senses1 = {}\n",
    "initial_senses2 = {}\n",
    "\n",
    "for l in attrs1:\n",
    "    x = data[data[col_name1] == l][[col_name1, right_col_name]]\n",
    "    selected_sense = init_assign(x, ssets, sense_dict)\n",
    "    initial_senses1[l] = selected_sense\n",
    "    print('x:\\n', x)\n",
    "\n",
    "for l in attrs2:\n",
    "    x = data[data[col_name2] == l][[col_name2, right_col_name]]\n",
    "    selected_sense = init_assign(x, ssets, sense_dict)\n",
    "    initial_senses2[l] = selected_sense\n",
    "    print('x:\\n', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_senses1:\n",
      " {'a1': '1', 'a2': '3'}\n",
      "initial_senses2:\n",
      " {'b1': '4', 'b2': '2', 'b3': '4'}\n"
     ]
    }
   ],
   "source": [
    "print('initial_senses1:\\n', initial_senses1)\n",
    "print('initial_senses2:\\n', initial_senses2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the dependency graph $G$.\n",
    "\n",
    "Compute the Earth Mover's Distance between overlapping classes ($u_1$, $u_2$) as edge weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attrs: ['a1' 'a2' 'b1' 'b2' 'b3']\n",
      "val1: ['c3', 'c6', 'c1', 'c2', 'c3', 'c4']\n",
      "val2: ['c3', 'c6']\n",
      "dist1: {'c3': 2, 'c1': 1, 'c6': 1, 'c4': 1, 'c2': 1}\n",
      "dist2: {'c3': 1, 'c1': 0, 'c6': 1, 'c4': 0, 'c2': 0}\n",
      "EMD: 0.7999999999999999\n",
      "val1: ['c3', 'c6', 'c1', 'c2', 'c3', 'c4']\n",
      "val2: ['c1', 'c2', 'c3', 'c4', 'c2', 'c4', 'c4']\n",
      "dist1: {'c3': 2, 'c1': 1, 'c6': 1, 'c4': 1, 'c2': 1}\n",
      "dist2: {'c3': 1, 'c1': 1, 'c6': 0, 'c4': 3, 'c2': 2}\n",
      "EMD: 0.6000000000000001\n",
      "val1: ['c2', 'c4', 'c4', 'c5', 'c3', 'c3']\n",
      "val2: ['c1', 'c2', 'c3', 'c4', 'c2', 'c4', 'c4']\n",
      "dist1: {'c3': 2, 'c1': 0, 'c5': 1, 'c4': 2, 'c2': 1}\n",
      "dist2: {'c3': 1, 'c1': 1, 'c5': 0, 'c4': 3, 'c2': 2}\n",
      "EMD: 0.19999999999999996\n",
      "val1: ['c2', 'c4', 'c4', 'c5', 'c3', 'c3']\n",
      "val2: ['c5', 'c3', 'c3']\n",
      "dist1: {'c5': 1, 'c4': 2, 'c2': 1, 'c3': 2}\n",
      "dist2: {'c5': 1, 'c4': 0, 'c2': 0, 'c3': 2}\n",
      "EMD: 0.75\n",
      "\n",
      "dependency graph: {0: [2, 3], 1: [3, 4], 2: [0], 3: [0, 1], 4: [1]}\n",
      "\n",
      "edge weight: {(0, 2): 0.7999999999999999, (2, 0): 0.7999999999999999, (0, 3): 0.6000000000000001, (3, 0): 0.6000000000000001, (1, 3): 0.19999999999999996, (3, 1): 0.19999999999999996, (1, 4): 0.75, (4, 1): 0.75}\n",
      "\n",
      "vertex weight: {0: 1.4, 1: 0.95, 2: 0.7999999999999999, 3: 0.8, 4: 0.75}\n",
      "\n",
      "sense assignment:\n",
      " {'a1': '1', 'a2': '3', 'b1': '4', 'b2': '2', 'b3': '4'}\n"
     ]
    }
   ],
   "source": [
    "from algorithms.dependency_graph import DependencyGraph\n",
    "\n",
    "G = DependencyGraph(data, initial_senses1, initial_senses2, attrs1, attrs2, sense_dict, right_col_name)\n",
    "G.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit nodes in decreasing order of their $EMD$ values by summing over all corresponding edges.\n",
    "\n",
    "Traverse G with BFS and refine the sense for each equivalence class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr1: a1\n",
      "attr2: b1\n",
      "x1:\n",
      "    ID   A   B   C\n",
      "0  t1  a1  b1  c3\n",
      "1  t2  a1  b1  c6\n",
      "2  t3  a1  b2  c1\n",
      "3  t4  a1  b2  c2\n",
      "4  t5  a1  b2  c3\n",
      "5  t6  a1  b2  c4\n",
      "x2:\n",
      "    ID   A   B   C\n",
      "0  t1  a1  b1  c3\n",
      "1  t2  a1  b1  c6\n",
      "\n",
      "synonyms: 1\n",
      "vals: ['c3', 'c6', 'c1', 'c2', 'c3', 'c4']\n",
      "outliers: ['c3', 'c1', 'c6', 'c4', 'c2']\n",
      "\n",
      "synonyms: 4\n",
      "vals: ['c3', 'c6', 'c1', 'c2', 'c3', 'c4']\n",
      "outliers: ['c3', 'c1', 'c6', 'c4', 'c2']\n",
      "\n",
      "synonyms: 4\n",
      "vals: ['c3', 'c6']\n",
      "outliers: ['c3', 'c6']\n",
      "\n",
      "synonyms: 1\n",
      "vals: ['c3', 'c6']\n",
      "outliers: ['c3', 'c6']\n",
      "\n",
      "synonyms: 1\n",
      "vals: ['c3', 'c6']\n",
      "outliers: ['c3', 'c6']\n",
      "\n",
      "synonyms: 4\n",
      "vals: ['c3', 'c6']\n",
      "outliers: ['c3', 'c6']\n",
      "val1: ['c3', 'c6', 'c1', 'c2', 'c3', 'c4']\n",
      "val2: ['c3', 'c6', 'c1', 'c2', 'c3', 'c4']\n",
      "dist1: {'c3': 2, 'c1': 1, 'c6': 1, 'c4': 1, 'c2': 1}\n",
      "dist2: {'c3': 2, 'c1': 1, 'c6': 1, 'c4': 1, 'c2': 1}\n",
      "EMD: 0.0\n",
      "attr1: a1\n",
      "attr2: b2\n",
      "x1:\n",
      "    ID   A   B   C\n",
      "0  t1  a1  b1  c3\n",
      "1  t2  a1  b1  c6\n",
      "2  t3  a1  b2  c1\n",
      "3  t4  a1  b2  c2\n",
      "4  t5  a1  b2  c3\n",
      "5  t6  a1  b2  c4\n",
      "x2:\n",
      "    ID   A   B   C\n",
      "2  t3  a1  b2  c1\n",
      "3  t4  a1  b2  c2\n",
      "4  t5  a1  b2  c3\n",
      "5  t6  a1  b2  c4\n",
      "6  t7  a2  b2  c2\n",
      "7  t8  a2  b2  c4\n",
      "8  t9  a2  b2  c4\n",
      "\n",
      "synonyms: 4\n",
      "vals: ['c3', 'c6', 'c1', 'c2', 'c3', 'c4']\n",
      "outliers: ['c3', 'c1', 'c6', 'c4', 'c2']\n",
      "\n",
      "synonyms: 2\n",
      "vals: ['c3', 'c6', 'c1', 'c2', 'c3', 'c4']\n",
      "outliers: ['c3', 'c1', 'c6', 'c4', 'c2']\n",
      "\n",
      "synonyms: 2\n",
      "vals: ['c1', 'c2', 'c3', 'c4', 'c2', 'c4', 'c4']\n",
      "outliers: ['c3', 'c1', 'c4', 'c2']\n",
      "\n",
      "synonyms: 4\n",
      "vals: ['c1', 'c2', 'c3', 'c4', 'c2', 'c4', 'c4']\n",
      "outliers: ['c3', 'c1', 'c4', 'c2']\n",
      "\n",
      "synonyms: 4\n",
      "vals: ['c1', 'c2', 'c3', 'c4']\n",
      "outliers: ['c3', 'c1', 'c4', 'c2']\n",
      "\n",
      "synonyms: 2\n",
      "vals: ['c1', 'c2', 'c3', 'c4']\n",
      "outliers: ['c3', 'c1', 'c4', 'c2']\n",
      "val1: ['c3', 'c6', 'c1', 'c2', 'c3', 'c4']\n",
      "val2: ['c3', 'c6', 'c1', 'c2', 'c3', 'c4']\n",
      "dist1: {'c3': 2, 'c1': 1, 'c6': 1, 'c4': 1, 'c2': 1}\n",
      "dist2: {'c3': 2, 'c1': 1, 'c6': 1, 'c4': 1, 'c2': 1}\n",
      "EMD: 0.0\n",
      "attr1: a2\n",
      "attr2: b3\n",
      "x1:\n",
      "      ID   A   B   C\n",
      "6    t7  a2  b2  c2\n",
      "7    t8  a2  b2  c4\n",
      "8    t9  a2  b2  c4\n",
      "9   t10  a2  b3  c5\n",
      "10  t11  a2  b3  c3\n",
      "11  t12  a2  b3  c3\n",
      "x2:\n",
      "      ID   A   B   C\n",
      "9   t10  a2  b3  c5\n",
      "10  t11  a2  b3  c3\n",
      "11  t12  a2  b3  c3\n",
      "\n",
      "synonyms: 3\n",
      "vals: ['c2', 'c4', 'c4', 'c5', 'c3', 'c3']\n",
      "outliers: ['c5', 'c4', 'c2', 'c3']\n",
      "\n",
      "synonyms: 4\n",
      "vals: ['c2', 'c4', 'c4', 'c5', 'c3', 'c3']\n",
      "outliers: ['c5', 'c4', 'c2', 'c3']\n",
      "\n",
      "synonyms: 4\n",
      "vals: ['c5', 'c3', 'c3']\n",
      "outliers: ['c5', 'c3']\n",
      "\n",
      "synonyms: 3\n",
      "vals: ['c5', 'c3', 'c3']\n",
      "outliers: ['c5', 'c3']\n",
      "\n",
      "synonyms: 3\n",
      "vals: ['c5', 'c3', 'c3']\n",
      "outliers: ['c5', 'c3']\n",
      "\n",
      "synonyms: 4\n",
      "vals: ['c5', 'c3', 'c3']\n",
      "outliers: ['c5', 'c3']\n",
      "val1: ['c2', 'c4', 'c4', 'c5', 'c3', 'c3']\n",
      "val2: ['c2', 'c4', 'c4', 'c5', 'c3', 'c3']\n",
      "dist1: {'c5': 1, 'c4': 2, 'c2': 1, 'c3': 2}\n",
      "dist2: {'c5': 1, 'c4': 2, 'c2': 1, 'c3': 2}\n",
      "EMD: 0.0\n",
      "\n",
      "dependency graph: {0: [2, 3], 1: [3, 4], 2: [0], 3: [0, 1], 4: [1]}\n",
      "\n",
      "edge weight: {(0, 2): 0.0, (2, 0): 0.0, (0, 3): 0.0, (3, 0): 0.0, (1, 3): 0.19999999999999996, (3, 1): 0.19999999999999996, (1, 4): 0.0, (4, 1): 0.0}\n",
      "\n",
      "vertex weight: {0: 1.4, 1: 0.95, 2: 0.7999999999999999, 3: 0.8, 4: 0.75}\n",
      "\n",
      "sense assignment:\n",
      " {'a1': '2', 'a2': '4', 'b1': '4', 'b2': '2', 'b3': '4'}\n"
     ]
    }
   ],
   "source": [
    "G.BFS()\n",
    "G.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data repair algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repair()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
