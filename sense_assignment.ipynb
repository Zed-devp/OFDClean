{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Read datasets and senses."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data:\n      ID   A   B   C\n0    t1  a1  b1  c3\n1    t2  a1  b1  c6\n2    t3  a1  b2  c1\n3    t4  a1  b2  c2\n4    t5  a1  b2  c3\n5    t6  a1  b2  c4\n6    t7  a2  b2  c2\n7    t8  a2  b2  c4\n8    t9  a2  b2  c4\n9   t10  a2  b3  c5\n10  t11  a2  b3  c3\n11  t12  a2  b3  c3\n\nsense_dict:\n {'1': ['c1', 'c2', 'c3'], '2': ['c2', 'c4'], '3': ['c1', 'c4', 'c5'], '4': ['c2', 'c3', 'c5'], '5': ['c1', 'c2', 'c5'], '6': ['c4', 'c6'], '7': ['c1', 'c4', 'c6', 'c7']}\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import read_data, sense2dict\n",
    "\n",
    "data_path = 'data.csv'\n",
    "senses_path = 'senses.csv'\n",
    "\n",
    "data, sense_dict = read_data(data_path, senses_path)\n",
    "\n",
    "print('data:\\n', data)\n",
    "print('\\nsense_dict:\\n', sense_dict)  # sense->synonym"
   ]
  },
  {
   "source": [
    "Convert sense table to ssets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ssets:\n {'c1': ['1', '3', '5', '7'], 'c2': ['1', '2', '4', '5'], 'c3': ['1', '4'], 'c4': ['2', '3', '6', '7'], 'c5': ['3', '4', '5'], 'c6': ['6', '7'], 'c7': ['7']}\n"
     ]
    }
   ],
   "source": [
    "ssets = {}  # synonym->sense\n",
    "for sense, synonym in sense_dict.items():\n",
    "    for value in synonym:\n",
    "        if value not in ssets.keys():\n",
    "            ssets[value] = []\n",
    "        ssets[value].append(sense)\n",
    "\n",
    "print('ssets:\\n', ssets)"
   ]
  },
  {
   "source": [
    "Initialize attribute columns here."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "attr1: ['b1' 'b2' 'b3']\nattr2: ['b1' 'b2' 'b3']\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import get_attribute\r\n",
    "\r\n",
    "col_name1 = 'A'\r\n",
    "attrs1 = get_attribute(data, col_name1)\r\n",
    "\r\n",
    "col_name2 = 'B'\r\n",
    "attrs2 = get_attribute(data, col_name2)\r\n",
    "\r\n",
    "right_col_name = 'C'\r\n",
    "\r\n",
    "print('attr1:', attrs1)\r\n",
    "print('attr2:', attrs2)"
   ]
  },
  {
   "source": [
    "Compute an initial assignment for every equivalence class $x$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x:\n     B   C\n0  b1  c3\n1  b1  c6\nk= 2\nsorted_synonyms ['c3', 'c6']\nsorted_senses [['1', '4'], ['6', '7']]\ntopk:\n [['1', '4'], ['6', '7']]\ntopk:\n [['1', '4']]\npotential_set: 1\nx:\n     B   C\n2  b2  c1\n3  b2  c2\n4  b2  c3\n5  b2  c4\n6  b2  c2\n7  b2  c4\n8  b2  c4\nk= 4\nsorted_synonyms ['c4', 'c2', 'c1', 'c3']\nsorted_senses [['2', '3', '6', '7'], ['1', '2', '4', '5'], ['1', '3', '5', '7'], ['1', '4']]\ntopk:\n [['2', '3', '6', '7'], ['1', '2', '4', '5'], ['1', '3', '5', '7'], ['1', '4']]\ntopk:\n [['2', '3', '6', '7'], ['1', '2', '4', '5'], ['1', '3', '5', '7']]\ntopk:\n [['2', '3', '6', '7'], ['1', '2', '4', '5']]\npotential_set: 2\nx:\n      B   C\n9   b3  c5\n10  b3  c3\n11  b3  c3\nk= 2\nsorted_synonyms ['c3', 'c5']\nsorted_senses [['1', '4'], ['3', '4', '5']]\ntopk:\n [['1', '4'], ['3', '4', '5']]\npotential_set: 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from algorithms.init_assign import init_assign\n",
    "\n",
    "initial_senses = {}\n",
    "\n",
    "for l in attrs1:\n",
    "    x = data[data[col_name1] == l][[col_name1, right_col_name]]\n",
    "    selected_sense = init_assign(x, ssets, sense_dict)\n",
    "\n",
    "    print('x:\\n', x)\n",
    "\n",
    "for l in attrs2:\n",
    "    x = data[data[col_name2] == l][[col_name2, right_col_name]]\n",
    "    selected_sense = init_assign(x, ssets, sense_dict)\n",
    "    \n",
    "    print('x:\\n', x)"
   ]
  },
  {
   "source": [
    "Construct the dependency graph $G$.\n",
    "\n",
    "Compute the Earth Mover's Distance between overlapping classes ($u_1$, $u_2$) as edge weights."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph = build_graph(test_data)\n",
    "print('graph:', test_graph)"
   ]
  },
  {
   "source": [
    "Visit nodes in decreasing order of their $EMD$ values by summing over all corresponding edges.\n",
    "\n",
    "BFS traverse."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_threshold = 0.2"
   ]
  },
  {
   "source": [
    "Refine the sense for each equivalence class."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimal_senses(test_data, sset)\n",
    "print('optimal_senses:', opt)\n",
    "\n",
    "'''example output\n",
    "senses: {1: '123', 2: '24', 3: '145', 4: '235', 5: '125'}\n",
    "graph: {0: [2], 1: [2, 3], 2: [0, 1], 3: [1]}\n",
    "optimal_senses: {0: [0], 1: [3], 2: [0, 1], 3: [3]}\n",
    "'''\n",
    "\n",
    "print('prob_table:\\n', prob_table(test_data, sset))\n",
    "\n",
    "KLtab = KL_table(test_graph, prob_table(test_data, sset))\n",
    "print('KL_table:', KLtab)\n",
    "\n",
    "# minKL(KLtab, optimal_senses(test_data, test_senses), test_threshold)\n",
    "#\n",
    "# BFS(test_graph, 0)\n",
    "\n",
    "# print('baseline:', baseline(KLtab, opt))\n",
    "\n",
    "sense_assign(test_graph, KLtab, opt)\n",
    "\n",
    "sense_assign(test_graph, KLtab, opt, test_threshold)"
   ]
  },
  {
   "source": [
    "Data repair algorithm."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repair()"
   ]
  }
 ]
}